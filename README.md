-----

# üîé Product Landing Page Crawler with LLM Analysis

An intelligent Node.js web crawler designed to find and extract multiple product names and descriptive keywords from e-commerce and content landing pages, leveraging local Large Language Models (LLMs) like **Ollama** (`mistral`).

-----

## ‚ú® Features

  * **Multiple Product Extraction**: Capable of extracting up to 10 distinct products per page. (More is possible if you accept a larger CSV file size.)
  * **Intelligent Classification**: The LLM understands how to distinguish actual product names from common webpage elements like navigation links, buttons, and decorative labels.
  * **Contextual Keywords**: Generates up to 10 relevant, categorization keywords for each identified product.
  * **Free & Open Source**: The core LLM analysis relies on **Ollama** (a free, open-source LLM runtime), avoiding paid API usage.

-----

## üèóÔ∏è Architecture

The project's architecture is divided into two primary approaches for content acquisition:

### Approach 1 (Chosen: Firecrawl for Data, Ollama for Analysis)

```
URL ‚Üí Fetch domain content (Firecrawl Crawl API) ‚Üí Extract Product Names ‚Üí Send names/description to LLM (Ollama, axios) to generate keywords
¬† ‚Üí Parse JSON Response ‚Üí CSV Output
```

### Approach 2 (Alternative: Direct Crawling/Scraping with Ollama)

```
URL ‚Üí Fetch HTML (axios) ‚Üí Extract Content (cheerio) ‚Üí Send raw content to LLM (Ollama)
¬† ‚Üí Parse JSON Response ‚Üí CSV Output
```

-----

## üß† Insights: Approach Selection Rationale

The project goals were centered around **deterministic results**, identifying product names/types, and generating categorization keywords. This led to testing three main approaches:

### 1\. DOM Parsing + Node.js NLP (`natural`)

| Pros ‚úÖ | Cons ‚ùå |
| :--- | :--- |
| Free and completely open source. | DOM parsing heuristics have limitations (e.g., misidentifying headers/labels as product names). |
| Deterministic results (same input always gives same output). | High complexity required to reach acceptable performance. |
| | Only achieved about **50% success rate** in identifying actual product names and useful keywords. |

### 2\. Direct LLM API (Ollama)

| Pros ‚úÖ | Cons ‚ùå |
| :--- | :--- |
| Highly accurate at distinguishing product names from headers/labels using natural language context. | **Non-deterministic results** (output varies based on model/user state). |
| Achieved much greater accuracy in identifying product names (only 3 URLs had issues). | Intensive use of the local GPU/CPU. |
| | Prone to **hallucinations** (e.g., outputting generic names like "Product 1" or regex-like strings for articles). |
| | Low success rate with identifying articles/blog post titles unless using a more powerful, paid model (like GPT-4/5). |

### 3\. Firecrawl API + Ollama (Chosen Approach)

This approach uses **Firecrawl** to handle the difficult, non-deterministic task of cleaning and structuring website content, and then feeds the high-quality content into **Ollama** for analysis.

  * **Firecrawl's Crawl Endpoint**: Used to recursively search and find URLs matching a pattern like `domain.com/products/.+`, and returns clean JSON content.
  * **The Trade-off**: Firecrawl ensures **deterministic results** (a key requirement) and provides the highest success rate of correct product names. This outweighs the financial cost (free credit limit).

> **Decision Summary:** **Firecrawl API** was chosen for **deterministic product name & description extraction**, and **Ollama** was chosen for **keyword generation** because the variation in keywords is acceptable because we get multiple keywords per product name.

-----

## üìù Setup Instructions

### Ollama (Local & Free LLM Runtime)

1.  **Download & Install Ollama**: [https://ollama.ai](https://ollama.ai)
2.  **Pull a model** (run in terminal):
    ```bash
    ollama pull mistral
    ```
    *(Other options: `neural-chat`, `llama2`, `orca-mini`)*
3.  **Start Ollama Server** (will run on `http://localhost:11434`):
    ```bash
    ollama serve
    ```

### Local Project Setup

1.  Install [Node.js](https://nodejs.org/).
2.  Navigate to your project folder containing `crawler.js` and `package.json`.
3.  **Install dependencies**:
    ```bash
    npm install
    ```
4.  **Set API Keys**:
      * **Direct Code Method (Less Secure):** If testing quickly, you may directly use the API key in `crawler.js` (e.g., `const firecrawl = new Firecrawl({ apiKey: "fc-..."});`). **Note:** The included key may have exhausted its free credits.
	  * A new API key can be generated by signing in at firecrawl.dev with any new email address.
	  * I am aware the recommended Secure Method is to use an environment variable by setting up a `.env` file (refer to the `.env.example` template). But I wanted to give you the option of not having to generate your own API key.
-----

## ‚ñ∂Ô∏è Usage

Ensure **Ollama is running** in a separate terminal (`ollama serve`), then execute the crawler from your project directory:

```bash
npm start
```

-----

## üìà Output

The script creates a CSV file based on the approach used:

  * **Firecrawl Approach**: `product_crawler_results_firecrawl.csv`
  * **Ollama Approach**: `product_crawler_results_ollama.csv` (can be produced when `crawler.js` is replaced with the ollama backup version)

### CSV Format

| \# | Column | Description |
| :--- | :--- | :--- |
| 1 | `URL` | The landing page URL. |
| 2 | `Product Name` | The actual product/article name identified by the LLM. |
| 3 | `Keywords` | Up to 10 comma-separated categorization keywords. |

-----

## ‚öôÔ∏è Customization

### Change Ollama Model

Edit the `OLLAMA_MODEL` constant in `crawler.js`:

```javascript
const OLLAMA_MODEL = 'mistral'; // Options: mistral, llama2, orca-mini
```

### Adjust Keywords Per Product

Modify the desired number of keywords directly within the LLM prompt string in `crawler.js`.

### Add/Remove URLs

Edit the `URLS` array defined in `crawler.js`.

-----

## ‚ùì Troubleshooting

### "Ollama error: connect ECONNREFUSED"

  * **Solution**: Make sure Ollama is running in another terminal (`ollama serve`) and is accessible at `http://localhost:11434`.

### "No JSON found in response"

  * **Cause**: The LLM model may be failing to follow the instruction to return ONLY a JSON array.
  * **Solution**: Try a different model (e.g., `ollama pull neural-chat`) or adjust the prompt engineering.

### Token Limit Exceeded

  * **Cause**: The input content is too large for the model's context window.
  * **Solution**: The script currently truncates content to 4000 characters. If this is still insufficient, you may need to reduce the content size further or use a model with a larger context window.

-----

## üêõ Known Issues & Proposed Solutions

### **Issue:** ran out of credits to call Firecrawl

We would need to pay to upgrade the API key to be able to use Firecrawl more.

### **Issue:** `9wik.com`, `inpeaceful.com`, `etherealing.com` show "product1", "product2", etc.

The current Ollama model struggles to extract titles from these complex, article-heavy, or heavily JavaScript-rendered sites.

  * **Proposed Solution**: **Pay money to use GPT-5.1 via the ChatGPT API**. Testing showed GPT-5.1 was able to successfully identify and extract rich product names from these difficult URLs:
      * **9wik.com**: Identified article titles (e.g., "Unleashing Performance: Exploring the Toyota GT Sports Car").
      * **inpeaceful.com**: Identified specific jewelry items (e.g., "925 Silver SImple Cuff Bracelet").
      * **etherealing.com**: Identified diverse products (e.g., "2 carat moissanite 925 Sterling Silver Pendant Necklace").

-----

## üì¶ Dependencies

  * **`axios`**: HTTP client for making API calls to Ollama and other services.
  * **`cheerio`**: HTML parsing library used in Approach 2.
  * **`firecrawl`**: Web crawling/scraping API for fetching clean, structured domain data (Approach 1).
  * **`Ollama`**: Local LLM runtime (external dependency).

-----

## ‚öñÔ∏è License

MIT
